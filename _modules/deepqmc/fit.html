
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>deepqmc.fit &#8212; DeepQMC 0.3.0 documentation</title>
    <link rel="stylesheet" href="../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/katex-math.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js"></script>
    <script src="../../_static/katex_autorenderer.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">DeepQMC</a></h1>



<p class="blurb">Deep-learning quantum Monte Carlo for electrons in real space</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=deepqmc&repo=deepqmc&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





    

<p>
<a class="badge" href="https://travis-ci.org/deepqmc/deepqmc">
    <img
        alt="https://secure.travis-ci.org/deepqmc/deepqmc.svg?branch=master"
        src="https://secure.travis-ci.org/deepqmc/deepqmc.svg?branch=master"
    />
</a>
</p>




    

<p>
<a class="badge" href="https://codecov.io/github/deepqmc/deepqmc">
    <img
    alt="https://codecov.io/github/deepqmc/deepqmc/coverage.svg?branch=master"
    src="https://codecov.io/github/deepqmc/deepqmc/coverage.svg?branch=master"
    />
</a>
</p>
<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cli.html">Command-line interface</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../refs.html">References</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for deepqmc.fit</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">contextlib</span> <span class="kn">import</span> <span class="n">nullcontext</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn.utils</span> <span class="kn">import</span> <span class="n">clip_grad_norm_</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>
<span class="kn">from</span> <span class="nn">uncertainties</span> <span class="kn">import</span> <span class="n">ufloat</span>

<span class="kn">from</span> <span class="nn">.errors</span> <span class="kn">import</span> <span class="n">DeepQMCError</span><span class="p">,</span> <span class="n">NanError</span>
<span class="kn">from</span> <span class="nn">.physics</span> <span class="kn">import</span> <span class="n">local_energy</span>
<span class="kn">from</span> <span class="nn">.torchext</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">estimate_optimal_batch_size_cuda</span><span class="p">,</span>
    <span class="n">is_cuda</span><span class="p">,</span>
    <span class="n">normalize_mean</span><span class="p">,</span>
    <span class="n">weighted_mean_var</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">__version__</span> <span class="o">=</span> <span class="s1">&#39;0.1.0&#39;</span>
<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;fit_wf&#39;</span><span class="p">,</span> <span class="s1">&#39;WaveFunctionLoss&#39;</span><span class="p">,</span> <span class="s1">&#39;LossEnergy&#39;</span><span class="p">]</span>

<span class="n">log</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="WaveFunctionLoss"><a class="viewcode-back" href="../../api.html#deepqmc.fit.WaveFunctionLoss">[docs]</a><span class="k">class</span> <span class="nc">WaveFunctionLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Base class for all wave function loss functions.</span>

<span class="sd">    Any such loss must be derived from the local energy and wave function</span>
<span class="sd">    values, :math:`L(\{E_\text{loc}[\psi],\ln|\psi|,w\})`, using also</span>
<span class="sd">    importance-sampling weights *w*.</span>

<span class="sd">    Shape:</span>
<span class="sd">        - Input1, :math:`E_\text{loc}[\psi](\mathbf r)`: :math:`(*)`</span>
<span class="sd">        - Input2, :math:`\ln|\psi(\mathbf r)|`: :math:`(*)`</span>
<span class="sd">        - Input3, :math:`w(\mathbf r)`: :math:`(*)`</span>
<span class="sd">        - Output, *L*: :math:`()`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">pass</span></div>


<div class="viewcode-block" id="LossEnergy"><a class="viewcode-back" href="../../api.html#deepqmc.fit.LossEnergy">[docs]</a><span class="k">class</span> <span class="nc">LossEnergy</span><span class="p">(</span><span class="n">WaveFunctionLoss</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Total energy loss function.</span>

<span class="sd">    .. math::</span>
<span class="sd">        L:=2\mathbb E\big[(E_\text{loc}-\mathbb E[E_\text{loc}])\ln|\psi|\big]</span>

<span class="sd">    Taking a derivative of only the logarithm, the resulting gradient is equivalent,</span>
<span class="sd">    thanks to the Hermitian property of the Hamiltonian, to the gradient of the</span>
<span class="sd">    plain total energy loss function, :math:`\mathbb E[E_\text{loc}]`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Es_loc</span><span class="p">,</span> <span class="n">log_psis</span><span class="p">,</span> <span class="n">ws</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">Es_loc</span><span class="o">.</span><span class="n">grad_fn</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">Es_loc</span> <span class="o">-</span> <span class="p">(</span><span class="n">ws</span> <span class="o">*</span> <span class="n">Es_loc</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">Es_loc</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">*</span> <span class="n">ws</span> <span class="o">*</span> <span class="n">log_psis</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span></div>


<span class="k">def</span> <span class="nf">log_clipped_outliers</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">q</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
    <span class="n">median</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">median</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">q</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
        <span class="n">x</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">sign</span><span class="p">()</span> <span class="o">*</span> <span class="n">a</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">/</span> <span class="n">a</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">))</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">median</span> <span class="o">+</span> <span class="n">x</span>


<div class="viewcode-block" id="fit_wf"><a class="viewcode-back" href="../../api.html#deepqmc.fit.fit_wf">[docs]</a><span class="k">def</span> <span class="nf">fit_wf</span><span class="p">(</span>  <span class="c1"># noqa: C901</span>
    <span class="n">wf</span><span class="p">,</span>
    <span class="n">loss_func</span><span class="p">,</span>
    <span class="n">opt</span><span class="p">,</span>
    <span class="n">sampler</span><span class="p">,</span>
    <span class="n">steps</span><span class="p">,</span>
    <span class="n">writer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">log_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">require_energy_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">require_psi_gradient</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">subbatch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_memory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">clip_outliers</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">q</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">max_grad_norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">kfac</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fit a wave function using the variational principle and gradient descent.</span>

<span class="sd">    This is a low-level interface, see :func:`~deepqmc.train` for a high-level</span>
<span class="sd">    interface. This iterator iteratively draws samples from the sampler, evaluates</span>
<span class="sd">    the local energy, processes outliers, calculates the loss function, and updates</span>
<span class="sd">    the wave function model parameters using a gradient of the loss and an</span>
<span class="sd">    optimizer. Diagnostics is written into the Tensorboard writer, and finally</span>
<span class="sd">    at the end of each iteration the step index is yielded, so that the caller</span>
<span class="sd">    can do some additional processing such as learning rate scheduling.</span>

<span class="sd">    Args:</span>
<span class="sd">        wf (:class:`~deepqmc.wf.WaveFunction`): wave function model to be fitted</span>
<span class="sd">        loss_func (:class:`WaveFunctionLoss`): loss function that accepts local</span>
<span class="sd">            energy and wave function values</span>
<span class="sd">        opt (:class:`torch.optim.Optimizer`): optimizer</span>
<span class="sd">        sampler (iterator): yields batches of electron coordinate samples</span>
<span class="sd">        steps (iterator): yields step indexes</span>
<span class="sd">        writer (:class:`torch.utils.tensorboard.writer.SummaryWriter`):</span>
<span class="sd">            Tensorboard writer</span>
<span class="sd">        log_dict (dict-like): batch data will be stored in this dictionary if given</span>
<span class="sd">        require_energy_gradient (bool): whether the loss function requires</span>
<span class="sd">            gradients of the local energy</span>
<span class="sd">        require_psi_gradient (bool): whether the loss function requires</span>
<span class="sd">            gradients of the wave function</span>
<span class="sd">        subbatch_size (int): number of samples for a single vectorized loss evaluation.</span>
<span class="sd">            If None and on a GPU, subbatch_size is estimated, else if None and on a CPU,</span>
<span class="sd">            no subbatching is done.</span>
<span class="sd">        max_memory (float): maximum amount of allocated GPU memory (MiB) to be</span>
<span class="sd">            considered if automatically estimating the subbatch_size. If :data:`None`</span>
<span class="sd">            and subbatch_size is estimated, the maximum memory is set to the total</span>
<span class="sd">            free GPU memory. When training on CPU always set to :data:`None`.</span>
<span class="sd">        clip_outliers (bool): whether to clip local energy outliers</span>
<span class="sd">        q (float): multiple of MAE defining outliers</span>
<span class="sd">        max_grad_norm (float): maximum gradient norm passed to</span>
<span class="sd">            :func:`torch.nn.utils.clip_grad_norm_`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_cuda</span><span class="p">(</span><span class="n">wf</span><span class="p">)</span> <span class="ow">and</span> <span class="n">max_memory</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DeepQMCError</span><span class="p">(</span>
            <span class="s1">&#39;Automatic subbatch_size estimation only implemented for GPU. &#39;</span>
            <span class="s1">&#39;When training on CPU, do not use max_memory.&#39;</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">is_cuda</span><span class="p">(</span><span class="n">wf</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">subbatch_size</span><span class="p">:</span>
        <span class="n">subbatch_size</span> <span class="o">=</span> <span class="n">estimate_optimal_batch_size_cuda</span><span class="p">(</span>
            <span class="n">partial</span><span class="p">(</span><span class="n">fit_wf_mem_test_func</span><span class="p">,</span> <span class="n">wf</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">,</span> <span class="n">require_psi_gradient</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">wf</span><span class="o">.</span><span class="n">n_up</span> <span class="o">+</span> <span class="n">wf</span><span class="o">.</span><span class="n">n_down</span><span class="p">),</span>
            <span class="n">max_memory</span><span class="o">=</span><span class="n">max_memory</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;estimated optimal subbatch size: </span><span class="si">{</span><span class="n">subbatch_size</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="p">(</span><span class="n">rs</span><span class="p">,</span> <span class="n">log_psi0s</span><span class="p">,</span> <span class="n">sign_psi0s</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="n">sampler</span><span class="p">):</span>
        <span class="n">rs_batch</span> <span class="o">=</span> <span class="n">rs</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">subbatch_size</span> <span class="o">=</span> <span class="n">subbatch_size</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">rs</span><span class="p">)</span>
        <span class="n">subbatches</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">rs</span><span class="p">,</span> <span class="n">log_psi0s</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">TensorDataset</span><span class="p">(</span><span class="n">rs</span><span class="p">,</span> <span class="n">log_psi0s</span><span class="p">,</span> <span class="n">sign_psi0s</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">subbatch_size</span>
        <span class="p">):</span>
            <span class="k">with</span> <span class="n">kfac</span><span class="o">.</span><span class="n">track_forward</span><span class="p">()</span> <span class="k">if</span> <span class="n">kfac</span> <span class="k">else</span> <span class="n">nullcontext</span><span class="p">():</span>
                <span class="n">Es_loc</span><span class="p">,</span> <span class="n">log_psis</span><span class="p">,</span> <span class="n">sign_psis</span> <span class="o">=</span> <span class="n">local_energy</span><span class="p">(</span>
                    <span class="n">rs</span><span class="p">,</span>
                    <span class="n">wf</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="kc">False</span><span class="p">),</span>
                    <span class="n">create_graph</span><span class="o">=</span><span class="n">require_energy_gradient</span><span class="p">,</span>
                    <span class="n">keep_graph</span><span class="o">=</span><span class="n">require_psi_gradient</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="n">log_ws</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">log_psis</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">log_psi0s</span>
            <span class="n">Es_loc_loss</span> <span class="o">=</span> <span class="n">log_clipped_outliers</span><span class="p">(</span><span class="n">Es_loc</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span> <span class="k">if</span> <span class="n">clip_outliers</span> <span class="k">else</span> <span class="n">Es_loc</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">Es_loc_loss</span><span class="p">,</span> <span class="n">log_psis</span><span class="p">,</span> <span class="n">normalize_mean</span><span class="p">(</span><span class="n">log_ws</span><span class="o">.</span><span class="n">exp</span><span class="p">()))</span>
            <span class="k">with</span> <span class="n">kfac</span><span class="o">.</span><span class="n">track_backward</span><span class="p">()</span> <span class="k">if</span> <span class="n">kfac</span> <span class="k">else</span> <span class="n">nullcontext</span><span class="p">():</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">kfac</span><span class="p">:</span>
                <span class="n">kfac</span><span class="o">.</span><span class="n">step_update</span><span class="p">(</span><span class="n">loss_func</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span>
            <span class="n">wf</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">subbatches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
                    <span class="n">Es_loc</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
                    <span class="n">Es_loc_loss</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
                    <span class="n">log_psis</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
                    <span class="n">sign_psis</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
                    <span class="n">log_ws</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">Es_loc</span><span class="p">,</span> <span class="n">Es_loc_loss</span><span class="p">,</span> <span class="n">log_psis</span><span class="p">,</span> <span class="n">sign_psis</span><span class="p">,</span> <span class="n">log_ws</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span> <span class="k">for</span> <span class="n">xs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">subbatches</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="k">raise</span> <span class="n">NanError</span><span class="p">(</span><span class="n">rs_batch</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">wf</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="n">NanError</span><span class="p">(</span><span class="n">rs_batch</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">max_grad_norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">wf</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_grad_norm</span><span class="p">)</span>
        <span class="n">E_loc_mean</span><span class="p">,</span> <span class="n">E_loc_var</span> <span class="o">=</span> <span class="n">weighted_mean_var</span><span class="p">(</span><span class="n">Es_loc</span><span class="p">,</span> <span class="n">log_ws</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span>
        <span class="n">E_loc_err</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">E_loc_var</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">Es_loc</span><span class="p">))</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="s1">&#39;param_groups&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">writer</span><span class="p">:</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;E_loc/mean&#39;</span><span class="p">,</span> <span class="n">E_loc_mean</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;E_loc/var&#39;</span><span class="p">,</span> <span class="n">E_loc_var</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;E_loc/min&#39;</span><span class="p">,</span> <span class="n">Es_loc</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">step</span><span class="p">)</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;E_loc/max&#39;</span><span class="p">,</span> <span class="n">Es_loc</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">step</span><span class="p">)</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;E_loc/err&#39;</span><span class="p">,</span> <span class="n">E_loc_err</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
            <span class="n">E_loc_loss_mean</span><span class="p">,</span> <span class="n">E_loc_loss_var</span> <span class="o">=</span> <span class="n">weighted_mean_var</span><span class="p">(</span>
                <span class="n">Es_loc_loss</span><span class="p">,</span> <span class="n">log_ws</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;E_loc_loss/mean&#39;</span><span class="p">,</span> <span class="n">E_loc_loss_mean</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;E_loc_loss/var&#39;</span><span class="p">,</span> <span class="n">E_loc_loss_var</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;log_weights/KLvar&#39;</span><span class="p">,</span> <span class="n">log_ws</span><span class="o">.</span><span class="n">var</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
            <span class="n">grads</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">wf</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;grad/norm&#39;</span><span class="p">,</span> <span class="n">grads</span><span class="o">.</span><span class="n">norm</span><span class="p">(),</span> <span class="n">step</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">wf</span><span class="o">.</span><span class="n">tracked_parameters</span><span class="p">():</span>
                <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;param/</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;misc/learning_rate&#39;</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;misc/batch_size&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">Es_loc</span><span class="p">),</span> <span class="n">step</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">log_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">log_dict</span><span class="p">[</span><span class="s1">&#39;E_loc&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Es_loc</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">log_dict</span><span class="p">[</span><span class="s1">&#39;E_loc_loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Es_loc_loss</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">log_dict</span><span class="p">[</span><span class="s1">&#39;log_psis&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">log_psis</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">log_dict</span><span class="p">[</span><span class="s1">&#39;sign_psis&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sign_psis</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">log_dict</span><span class="p">[</span><span class="s1">&#39;log_ws&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">log_ws</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">log_dict</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="k">if</span> <span class="n">kfac</span><span class="p">:</span>
            <span class="n">kfac</span><span class="o">.</span><span class="n">step_precondition</span><span class="p">()</span>
            <span class="n">fnorm</span><span class="p">,</span> <span class="n">gnorm</span> <span class="o">=</span> <span class="n">kfac</span><span class="o">.</span><span class="n">step_rescale</span><span class="p">()</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;kfac/KL&#39;</span><span class="p">,</span> <span class="n">fnorm</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;kfac/dE&#39;</span><span class="p">,</span> <span class="o">-</span><span class="n">gnorm</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">yield</span> <span class="n">step</span><span class="p">,</span> <span class="n">ufloat</span><span class="p">(</span><span class="n">E_loc_mean</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">E_loc_err</span><span class="o">.</span><span class="n">item</span><span class="p">())</span></div>


<span class="k">def</span> <span class="nf">fit_wf_mem_test_func</span><span class="p">(</span><span class="n">wf</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">,</span> <span class="n">require_psi_gradient</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="c1"># require_energy_gradient isn&#39;t needed here because it adds only little</span>
    <span class="c1"># extra memory to the probe calculation</span>
    <span class="k">assert</span> <span class="n">is_cuda</span><span class="p">(</span><span class="n">wf</span><span class="p">)</span>
    <span class="n">rs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">size</span><span class="p">,</span> <span class="n">wf</span><span class="o">.</span><span class="n">n_down</span> <span class="o">+</span> <span class="n">wf</span><span class="o">.</span><span class="n">n_up</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">E_loc</span><span class="p">,</span> <span class="n">log_psi</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">local_energy</span><span class="p">(</span><span class="n">rs</span><span class="p">,</span> <span class="n">wf</span><span class="p">,</span> <span class="n">keep_graph</span><span class="o">=</span><span class="n">require_psi_gradient</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span>
        <span class="n">E_loc</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="k">if</span> <span class="n">require_psi_gradient</span> <span class="k">else</span> <span class="n">E_loc</span><span class="p">,</span> <span class="n">log_psi</span><span class="p">,</span> <span class="n">rs</span><span class="o">.</span><span class="n">new_ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rs</span><span class="p">))</span>
    <span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>

          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2019-2021, Frank No√© and collaborators.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.4.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
    </div>

    

    
  </body>
</html>